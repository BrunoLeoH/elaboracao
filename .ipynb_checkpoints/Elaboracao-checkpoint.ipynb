{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a68a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elaboração Desenvolvimento de Controle de Qualidade para Questionários da Área da Saúde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d32e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ben10\\anaconda3\\lib\\site-packages (1.82.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n",
      "Requirement already satisfied: google-cloud-speech in c:\\users\\ben10\\anaconda3\\lib\\site-packages (2.32.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-cloud-speech) (2.24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-cloud-speech) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-cloud-speech) (1.26.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-cloud-speech) (2.40.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (2.28.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.71.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (5.5.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ben10\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (2.0.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\ben10\\anaconda3\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "#Protótipo de Elaboração : Sistema de Controle de Qualidade para Questionários em Estudos de Saúde e Epidemiologia\n",
    "!pip install openai\n",
    "!pip install google-cloud-speech\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbbfd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ben10\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d58d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 1: IMPORTAÇÃO DE BIBLIOTECAS\n",
    "import os\n",
    "import csv\n",
    "import openai\n",
    "from google.cloud import speech\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74f7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 2: CONFIGURAÇÕES INICIAIS\n",
    "\n",
    "# Caminho para o arquivo de credenciais da Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:\\\\Users\\\\ben10\\\\Downloads\\\\prototipo-de-elaboracao-1be26843005f.json\"\n",
    "\n",
    "# Chave da API OpenAI\n",
    "#openai.api_key = \"sua_openai_key\"\n",
    "\n",
    "# Nome do arquivo de áudio e CSV\n",
    "#AUDIO_FILE = \"exemplo_audio.wav\"\n",
    "#PERGUNTAS_CSV = \"perguntas.csv\"\n",
    "\n",
    "#você já pode usar pydub para converter arquivos para .wav, como por exemplo:\n",
    "#audio = AudioSegment.from_mp3(\"seuarquivo.mp3\")\n",
    "#audio.export(\"convertido.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 3: LEITURA DAS PERGUNTAS\n",
    "\n",
    "df_perguntas = pd.read_csv(PERGUNTAS_CSV)\n",
    "print(\"Perguntas carregadas:\")\n",
    "print(df_perguntas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f941dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 4: TRANSCRIÇÃO COM GOOGLE CLOUD SPEECH-TO-TEXT\n",
    "\n",
    "def transcreve_audio_google(audio_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,  # ou conforme o arquivo\n",
    "        language_code=\"pt-BR\",\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    transcript = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
    "    return transcript\n",
    "\n",
    "#transcricao = transcreve_audio_google(AUDIO_FILE)\n",
    "#print(\"Transcrição do áudio:\")\n",
    "#print(transcricao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e802f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 5: ANÁLISE COM LLM GPT-4o (OpenAI)\n",
    "\n",
    "def organiza_respostas(transcricao, perguntas):\n",
    "    prompt = f\"\"\"\n",
    "    Abaixo está a transcrição de uma entrevista em português, seguida de uma lista de perguntas realizadas na entrevista.\n",
    "\n",
    "    Transcrição:\n",
    "    {transcricao}\n",
    "\n",
    "    Perguntas:\n",
    "    {', '.join(perguntas)}\n",
    "\n",
    "    Sua tarefa é organizar as respostas correspondentes a cada pergunta de forma clara, mesmo que a ordem esteja diferente.\n",
    "    Para cada pergunta, extraia a resposta correspondente da transcrição e escreva no formato:\n",
    "    \n",
    "    Pergunta: ...\n",
    "    Resposta: ...\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "resposta_final = organiza_respostas(transcricao, df_perguntas['pergunta'].tolist())\n",
    "print(\"Resposta organizada:\")\n",
    "print(resposta_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'audio_data' já foi carregado e 'dialogo_csv_data' contém o conteúdo do CSV\n",
    "# Ex: dialogos = [{\"pergunta_esperada\": \"Qual o seu nome?\", \"resposta_esperada\": \"Meu nome é Bruno.\"}]\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# ---- Configuração ----\n",
    "# ATENÇÃO: Nunca deixe sua chave diretamente no código em produção! Use variáveis de ambiente.\n",
    "# Este é um exemplo para fins de prototipagem.\n",
    "os.environ['OPENAI_API_KEY'] = 'SUA_CHAVE_DA_OPENAI_AQUI'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"C:\\\\Users\\\\ben10\\\\Downloads\\\\prototipo-de-elaboracao-1be26843005f.json\" # Exemplo do caminho corrigido\n",
    "\n",
    "# Inicializa o cliente OpenAI\n",
    "client_openai = OpenAI()\n",
    "\n",
    "# Inicializa o cliente Google Cloud Speech-to-Text\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "client_google_speech = speech.SpeechClient()\n",
    "\n",
    "# Caminho para o áudio de teste local (simulação da entrevista)\n",
    "audio_file_path = \"caminho/para/seu/audio_curto_teste.wav\" # Certifique-se de usar um caminho real\n",
    "\n",
    "# Caminho para o arquivo CSV com perguntas e respostas esperadas\n",
    "csv_file_path = \"caminho/para/seu/perguntas_respostas_esperadas.csv\" # Certifique-se de usar um caminho real\n",
    "\n",
    "# ---- Função para carregar áudio (Exemplo simplificado) ----\n",
    "def load_audio_content(file_path):\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    return content\n",
    "\n",
    "# ---- Função para carregar CSV (Exemplo simplificado) ----\n",
    "import csv\n",
    "def load_csv_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "# ---- Função para transcrever áudio com Google Speech-to-Text ----\n",
    "def transcribe_audio_google(audio_content, sample_rate_hertz=16000, language_code=\"pt-BR\"):\n",
    "    audio = speech.RecognitionAudio(content=audio_content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, # Ajuste conforme seu áudio\n",
    "        sample_rate_hertz=sample_rate_hertz,\n",
    "        language_code=language_code,\n",
    "        model=\"default\" # Pode ser \"latest_long\" ou \"phone_call\" dependendo do áudio\n",
    "    )\n",
    "    try:\n",
    "        response = client_google_speech.recognize(config=config, audio=audio)\n",
    "        transcription = \"\"\n",
    "        for result in response.results:\n",
    "            transcription += result.alternatives[0].transcript\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na transcrição do Google Speech-to-Text: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---- Função para processar com OpenAI LLM ----\n",
    "def process_with_openai_llm(prompt_text, model=\"gpt-4o\"):\n",
    "    try:\n",
    "        response = client_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Você é um assistente útil para analisar a coerência entre perguntas e respostas de entrevistas.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text}\n",
    "            ],\n",
    "            temperature=0.7 # Ajuste para controlar a criatividade\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no processamento com OpenAI LLM: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---- Fluxo Principal do Protótipo ----\n",
    "def run_prototype():\n",
    "    print(\"Iniciando o protótipo...\")\n",
    "\n",
    "    # 1. Carregar áudio local\n",
    "    audio_content = load_audio_content(audio_file_path)\n",
    "    if not audio_content:\n",
    "        print(\"Não foi possível carregar o arquivo de áudio. Verifique o caminho.\")\n",
    "        return\n",
    "\n",
    "    # 2. Transcrever áudio\n",
    "    print(\"Transcrevendo áudio com Google Speech-to-Text...\")\n",
    "    transcricao_completa = transcribe_audio_google(audio_content)\n",
    "    if not transcricao_completa:\n",
    "        print(\"Transcrição falhou. Encerrando protótipo.\")\n",
    "        return\n",
    "    print(f\"Transcrição completa do áudio: {transcricao_completa}\\n\")\n",
    "\n",
    "    # 3. Carregar perguntas e respostas esperadas do CSV\n",
    "    perguntas_respostas_esperadas = load_csv_data(csv_file_path)\n",
    "    if not perguntas_respostas_esperadas:\n",
    "        print(\"Não foi possível carregar o arquivo CSV. Verifique o caminho ou o formato.\")\n",
    "        return\n",
    "\n",
    "    resultados_finais = []\n",
    "\n",
    "    # 4. Loop para sincronização e processamento com LLM\n",
    "    print(\"Iniciando loop de sincronização e processamento com OpenAI LLM...\")\n",
    "    for i, par in enumerate(perguntas_respostas_esperadas):\n",
    "        pergunta_escrita = par.get(\"pergunta_esperada\", \"\")\n",
    "        resposta_escrita = par.get(\"resposta_esperada\", \"\")\n",
    "\n",
    "        # SIMPLIFICAÇÃO: Lógica de sincronização básica para o protótipo.\n",
    "        # Em um sistema real, isso envolveria algoritmos de alinhamento de texto/áudio.\n",
    "        # Aqui, estamos simplesmente assumindo que podemos \"identificar\" as partes na transcrição completa.\n",
    "        # Para um protótipo, você pode até passar a transcrição completa e pedir ao LLM para \"extrair\"\n",
    "        # a resposta para uma pergunta específica e compará-la com a esperada.\n",
    "        \n",
    "        # Exemplo de prompt simplificado para o LLM para simular a sincronização e análise\n",
    "        prompt_para_llm_para_analise = (\n",
    "            f\"Considere a seguinte pergunta de questionário: '{pergunta_escrita}'\\n\"\n",
    "            f\"A resposta esperada é: '{resposta_escrita}'\\n\"\n",
    "            f\"A transcrição completa do áudio é: '{transcricao_completa}'\\n\\n\"\n",
    "            f\"1. Identifique a resposta mais provável para a pergunta '{pergunta_escrita}' dentro da 'transcrição completa'.\\n\"\n",
    "            f\"2. Compare a resposta identificada na transcrição com a 'resposta esperada'.\\n\"\n",
    "            f\"3. Avalie a coerência e a fidelidade da resposta identificada. Atribua uma pontuação de 0 a 100 para a qualidade da correspondência.\\n\"\n",
    "            f\"4. Sugira ajustes na resposta da transcrição para que ela corresponda melhor à resposta esperada, se necessário.\"\n",
    "        )\n",
    "\n",
    "        print(f\"\\nProcessando Par {i+1}: Pergunta='{pergunta_escrita}' Resposta Esperada='{resposta_escrita}'\")\n",
    "        analise_llm = process_with_openai_llm(prompt_para_llm_para_analise)\n",
    "        \n",
    "        resultado_par = {\n",
    "            \"pergunta_escrita\": pergunta_escrita,\n",
    "            \"resposta_escrita\": resposta_escrita,\n",
    "            \"transcricao_completa_audio\": transcricao_completa, # Manter a completa por enquanto\n",
    "            \"analise_llm\": analise_llm\n",
    "        }\n",
    "        resultados_finais.append(resultado_par)\n",
    "        print(f\"Análise do LLM para o par {i+1}:\\n{analise_llm}\")\n",
    "\n",
    "    # 5. Salvar resultados\n",
    "    import json\n",
    "    output_json_path = \"resultados_prototipo.json\"\n",
    "    with open(output_json_path, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(resultados_finais, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"\\nProtótipo concluído. Resultados salvos em: {output_json_path}\")\n",
    "\n",
    "# Executar o protótipo\n",
    "if __name__ == \"__main__\":\n",
    "    # CRIE SEUS ARQUIVOS DE ÁUDIO E CSV DE TESTE ANTES DE EXECUTAR!\n",
    "    # Exemplo de conteúdo para 'perguntas_respostas_esperadas.csv':\n",
    "    # pergunta_esperada,resposta_esperada\n",
    "    # Qual o seu nome?,Meu nome é Bruno.\n",
    "    # Qual a sua idade?,Tenho 25 anos.\n",
    "\n",
    "    # Certifique-se de que o audio_file_path e csv_file_path apontem para arquivos existentes\n",
    "    # e que suas chaves de API estejam configuradas.\n",
    "    run_prototype()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
